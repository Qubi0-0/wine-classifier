{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "1. The main goal of project is to solve wine classification problem using machine learning algorithms.\n",
    "We will try to predict wine quality based on its features. For that we will use supervised learning algorithms: \n",
    "- Decision Trees\n",
    "- Multilayer Perceptron\n",
    "- K-Nearest Neighbors\n",
    "\n",
    "For this purpose, we will use the [Wine Quality Data Set](https://archive.ics.uci.edu/ml/datasets/wine+quality) from UCI Machine Learning Repository. The dataset consists of 4898 instances of white wine and 1599 of red wine. The dataset contains 11 features and 1 target variable. The target variable is quality of wine. The quality is a score between 0 and 10. The higher score means better quality. The features are:\n",
    "\n",
    "* fixed acidity\n",
    "* volatile acidity\n",
    "* citric acid\n",
    "* residual sugar\n",
    "* chlorides\n",
    "* free sulfur dioxide\n",
    "* total sulfur dioxide\n",
    "* density\n",
    "* pH\n",
    "* sulphates\n",
    "* alcohol\n",
    "\n",
    "2. The project is divided into 3 parts:\n",
    "* Data preprocessing\n",
    "* Classification\n",
    "* Evaluation\n",
    "\n",
    "3. The project is written in Python 3.11.5. The following libraries are used:\n",
    "* numpy\n",
    "* pandas\n",
    "* matplotlib\n",
    "* seaborn\n",
    "* sklearn\n",
    "* copy\n",
    "* os \n",
    "* sklearn\n",
    "    \n",
    "All libraries can be installed using pip. There is a requirements.txt file in the project folder. To install all libraries, run the following command in the project folder: `pip install -r requirements.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "The understanding of the dataset was done in VisualExplore.ipynb notebook. It includes basic statistics presentation, correlation analysis, quality distributions, box plots for outlier detection, and the application of the Recursive Feature Elimination method to identify key features. All the code and results are presented there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "For that purpose we will: \n",
    "* Randomly remove 10%, 20%, and 30% of the values of the features of each dataset and\n",
    "explore two different strategies to handle missing values;\n",
    "* Experiment with data normalization and data discretization methods. Apply these steps to the original, unchanged, dataset.\n",
    "\n",
    "All the following steps are done in Separate notebooks for clarity of the code. The notebooks are named as follows:\n",
    "* RandomRemove.ipynb\n",
    "* DataNormDisc.ipynb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "For that purpose we will use the following algorithms:\n",
    "* Decision Trees\n",
    "* Multilayer Perceptron\n",
    "* K-Nearest Neighbors\n",
    "\n",
    "All the following steps are done in Separate notebooks for clarity of the code. The notebooks are named as follows:\n",
    "* DecisionTrees.ipynb\n",
    "* MPL.ipynb\n",
    "* KNN.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "## Datset evaluation\n",
    "The most important thing about the dataset is the imbalance of the target variable. The dataset contains quality from 3 to 9. However the quality is from 0-10. Most of the values are 5 and 6 with a huge disproportion to the other values. \n",
    "\n",
    "## Decision Trees\n",
    "The model looked very promising after SMOTE oversampling. The model has high accuracy. \n",
    "\n",
    "## Multilayer Perceptron\n",
    "The model performs quite well, particularly following data normalization and balancing through SMOTE data augmentation, achieving noteworthy accuracy rates of 87% on the red wine dataset and 78% on the white wine dataset. A comprehensive overview of all experiments and conclusions can be found in the MLP.ipynb notebook.\n",
    "\n",
    "\n",
    "## K-Nearest Neighbors\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
