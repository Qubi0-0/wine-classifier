{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Project\n",
    "\n",
    "#### The main goal of the project was to solve the wine classification problem using machine learning algorithms. We aimed to predict wine quality category based on its features. For this, we used supervised learning algorithms: \n",
    "- Decision Trees\n",
    "- Multilayer Perceptron\n",
    "- K-Nearest Neighbors\n",
    "\n",
    "We utilized the [Wine Quality Data Set](https://archive.ics.uci.edu/ml/datasets/wine+quality) from the UCI Machine Learning Repository. The dataset consisted of 4898 instances of white wine and 1599 of red wine. It contained 11 features and 1 target variable. The target variable was the quality of the wine, a score between 0 and 10, with a higher score indicating better quality. The features were:\n",
    "\n",
    "* fixed acidity\n",
    "* volatile acidity\n",
    "* citric acid\n",
    "* residual sugar\n",
    "* chlorides\n",
    "* free sulfur dioxide\n",
    "* total sulfur dioxide\n",
    "* density\n",
    "* pH\n",
    "* sulphates\n",
    "* alcohol\n",
    "\n",
    "#### The project was divided into 3 parts:\n",
    "* Data preprocessing\n",
    "* Classification\n",
    "* Evaluation\n",
    "\n",
    "#### The project was written in Python 3.11.5. The following libraries were used:\n",
    "* numpy\n",
    "* pandas\n",
    "* matplotlib\n",
    "* seaborn\n",
    "* sklearn\n",
    "* copy\n",
    "* os \n",
    "* sklearn\n",
    "* imblearn\n",
    "* warnings\n",
    "* copy\n",
    "\n",
    "All libraries could be installed using pip. There was a requirements.txt file in the project folder. To install all libraries, the following command was run in the project folder: `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Understanding\n",
    "\n",
    "The understanding of the dataset was done in `VisualExplore.ipynb` notebook and all the code and results are presented there. It includes basic statistics presentation, correlation analysis, quality distributions, box plots for outlier detection, and the application of the Recursive Feature Elimination method to identify key features. The crucial aspect of the dataset lies in the imbalance of the target variable, ranging from quality scores 3 to 9 within a scale of 0-10. Notably, the dataset is heavily skewed towards values 5 and 6, creating a significant disproportion compared to other quality scores. This imbalance poses potential challenges for various classifiers, potentially leading to a decline in overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Different techniques were applied to the dataset: \n",
    "* Randomly removing 10%, 20%, and 30% of the values of the features of each dataset and\n",
    "exploring two different strategies to handle missing values.\n",
    "* Experiment with data normalization and data discretization methods.\n",
    "\n",
    "All the following steps are done in Separate notebooks for clarity of the code. The notebooks are named as follows:\n",
    "\n",
    "* `RandomRemove.ipynb`\n",
    "* `DataNormDisc.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "For that purpose we used the following algorithms:\n",
    "* Decision Trees\n",
    "* Multilayer Perceptron\n",
    "* K-Nearest Neighbors\n",
    "\n",
    "All the following steps are done in Separate notebooks for clarity of the code. The notebooks are named as follows:\n",
    "* DecisionTrees.ipynb\n",
    "* MPL.ipynb\n",
    "* KNN.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "### Decision Trees\n",
    "The model demonstrated high accuracy, particularly with the white wine dataset. Its optimal performance was achieved using SMOTE oversampling. Feature selection had minimal impact, and due to the algorithm's nature, normalization didn't affect the results. The model's performance declined when data was missing but improved upon restoration, but still not to the level of the original dataset.\n",
    "\n",
    "The overview of experiments and conclusions is presented in the `DecistionTrees.ipynb` notebook.\n",
    "\n",
    "### Multilayer Perceptron\n",
    "The model performs quite well, particularly following data normalization and balancing through SMOTE data augmentation, achieving noteworthy accuracy rates of 87% on the red wine dataset and 78% on the white wine dataset. In general normalization improves model's accuracy. The model exhibits reduced performance when faced with instances where data has been removed and subsequently restored. Selecting the most crucial features did not yield a significant improvement. \n",
    "\n",
    "A comprehensive overview of all experiments and conclusions can be found in the `MLP.ipynb` notebook.\n",
    "\n",
    "\n",
    "### K-Nearest Neighbors\n",
    "\n",
    "The model performs very good. The accuracy reaches 86% for red wine and 82% for white wine. The best results are achieved after SMOTE oversampling and data normalization. Diffferent values of k were tested. The best results were achieved for k=5. K=3 showed similar results. K=7 showed slightly worse results. Any work with dealing with missing values did not improve the results, however restoring missing values with mean values showed promising results in case of missing values in the dataset.\n",
    "\n",
    "More details can be found in `KNN.ipynb` notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Contribution\n",
    "\n",
    "The work was done by the following team members:\n",
    "* Jakub Zeifert (50%)\n",
    "* Krzysztof Lewandowski (50%)\n",
    "\n",
    "We worked together on all parts of the project. \n",
    "We had regular meetings to discuss the progress and to make decisions. \n",
    "We both were checking each other's code and results. We both were writing the report. We both were working on the presentation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
