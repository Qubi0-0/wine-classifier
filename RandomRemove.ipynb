{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset: (1599, 12)\n",
      "Null values found in dataset\n",
      "shape of dataset: (1599, 12)\n",
      "Null values found in dataset\n",
      "shape of dataset: (1599, 12)\n",
      "Null values found in dataset\n",
      "shape of dataset: (4898, 12)\n",
      "Null values found in dataset\n",
      "shape of dataset: (4898, 12)\n",
      "Null values found in dataset\n",
      "shape of dataset: (4898, 12)\n",
      "Null values found in dataset\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "data_red = pd.read_csv('data/full/winequality-red.csv', delimiter=';')\n",
    "data_white = pd.read_csv('data/full/winequality-white.csv', delimiter=';')\n",
    "np.random.seed(42)\n",
    "def create_sampled_datasets(dataset):\n",
    "\n",
    "    dataset_sampled_10 = dataset.copy()\n",
    "    dataset_sampled_20 = dataset.copy()\n",
    "    dataset_sampled_30 = dataset.copy()\n",
    "\n",
    "    sampled_datasets = [dataset_sampled_10, dataset_sampled_20, dataset_sampled_30]\n",
    "\n",
    "    for sampled_dataset, fraction in [(dataset_sampled_10, 0.1), (dataset_sampled_20, 0.2), (dataset_sampled_30, 0.3)]:\n",
    "        for col in sampled_dataset.columns:\n",
    "            mask = np.random.rand(sampled_dataset.shape[0]) <= fraction\n",
    "            sampled_dataset.loc[mask, col] = np.nan\n",
    "\n",
    "        print(f\"shape of dataset: {sampled_dataset.shape}\")\n",
    "        if sampled_dataset.isnull().sum().sum() > 0:\n",
    "            print(\"Null values found in dataset\")\n",
    "        else:\n",
    "            print(\"No null values found in dataset\")\n",
    "\n",
    "    return sampled_datasets\n",
    "\n",
    "sampled_datasets_red = create_sampled_datasets(data_red)\n",
    "sampled_datasets_white = create_sampled_datasets(data_white)\n",
    "\n",
    "sampled_datasets = [sampled_datasets_red, sampled_datasets_white]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For easier operations on datasets, they were converted to pandas dataframes. Then all of them were saved to a list called `datasets`. The first elements of the list are red samples, and the rest are the datasets are white samples. It will make it easier to iterate over them. Then the code puts Null values to random places to make it a missing value. Now we can try different methods to handle missing values.\n",
    "\n",
    "# Handling Missing Values\n",
    "\n",
    "There are many ways to handle missing values in a dataset. In this notebook, I will use the simplest one: removing the rows with missing values. I will use the `dropna()` method of pandas dataframes to remove the rows with missing values. I will use the `inplace=True` parameter to make the changes permanent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in dataset before removal: 1947\n",
      "shape of dataset: (1599, 12)\n",
      "Null values in dataset after removal: 0\n",
      "reduced shape of dataset: (453, 12) \n",
      "\n",
      "Null values in dataset before removal: 3787\n",
      "shape of dataset: (1599, 12)\n",
      "Null values in dataset after removal: 0\n",
      "reduced shape of dataset: (136, 12) \n",
      "\n",
      "Null values in dataset before removal: 5787\n",
      "shape of dataset: (1599, 12)\n",
      "Null values in dataset after removal: 0\n",
      "reduced shape of dataset: (19, 12) \n",
      "\n",
      "Null values in dataset before removal: 5900\n",
      "shape of dataset: (4898, 12)\n",
      "Null values in dataset after removal: 0\n",
      "reduced shape of dataset: (1410, 12) \n",
      "\n",
      "Null values in dataset before removal: 11737\n",
      "shape of dataset: (4898, 12)\n",
      "Null values in dataset after removal: 0\n",
      "reduced shape of dataset: (359, 12) \n",
      "\n",
      "Null values in dataset before removal: 17603\n",
      "shape of dataset: (4898, 12)\n",
      "Null values in dataset after removal: 0\n",
      "reduced shape of dataset: (66, 12) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_datasets_removal = copy.deepcopy(sampled_datasets)\n",
    "for datasets in sampled_datasets_removal:\n",
    "    for dataset in datasets:\n",
    "        print(f\"Null values in dataset before removal: {dataset.isnull().sum().sum()}\")\n",
    "        print(f\"shape of dataset: {dataset.shape}\")\n",
    "        dataset.dropna(inplace=True)\n",
    "        print(f\"Null values in dataset after removal: {dataset.isnull().sum().sum()}\")\n",
    "        print(f\"reduced shape of dataset: {dataset.shape} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the code removed all null values from the dataset. We lost a lot of rows, that could potentially be restored. Now one of the sets has only 19 rows of data which is so small, that it is almost impossible to train a model on it. Let's try to restore the missing values. \n",
    "\n",
    "# Restoring Missing Values\n",
    "\n",
    "There are many ways to restore missing values. In this notebook, I will use the simplest one: replacing the missing values with the mean of the column. I will use the `fillna()` method of pandas dataframes to replace the missing values with the mean of the column. I will use the `inplace=True` parameter to make the changes permanent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values in dataset before restore: 1947\n",
      "shape of dataset: (1599, 12)\n",
      "Null values in dataset after restore: 0\n",
      "reduced shape of dataset: (1599, 12) \n",
      "\n",
      "Null values in dataset before restore: 3787\n",
      "shape of dataset: (1599, 12)\n",
      "Null values in dataset after restore: 0\n",
      "reduced shape of dataset: (1599, 12) \n",
      "\n",
      "Null values in dataset before restore: 5787\n",
      "shape of dataset: (1599, 12)\n",
      "Null values in dataset after restore: 0\n",
      "reduced shape of dataset: (1599, 12) \n",
      "\n",
      "Null values in dataset before restore: 5900\n",
      "shape of dataset: (4898, 12)\n",
      "Null values in dataset after restore: 0\n",
      "reduced shape of dataset: (4898, 12) \n",
      "\n",
      "Null values in dataset before restore: 11737\n",
      "shape of dataset: (4898, 12)\n",
      "Null values in dataset after restore: 0\n",
      "reduced shape of dataset: (4898, 12) \n",
      "\n",
      "Null values in dataset before restore: 17603\n",
      "shape of dataset: (4898, 12)\n",
      "Null values in dataset after restore: 0\n",
      "reduced shape of dataset: (4898, 12) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_datasets_restored = copy.deepcopy(sampled_datasets)\n",
    "for datasets in sampled_datasets_restored:\n",
    "    for dataset in datasets:\n",
    "        print(f\"Null values in dataset before restore: {dataset.isnull().sum().sum()}\")\n",
    "        print(f\"shape of dataset: {dataset.shape}\")\n",
    "        dataset.fillna(dataset.mean(), inplace=True)\n",
    "        print(f\"Null values in dataset after restore: {dataset.isnull().sum().sum()}\")\n",
    "        print(f\"reduced shape of dataset: {dataset.shape} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did not loose any data. The gaps are filled with the mean of the column. Now we can try to train a model on the data. This method is not the best one, but it is the simplest one. If there are not many missing values or the values do not differ very much from each other, this method is a good choice. If the values differ a lot, this method will not work well. \n",
    "\n",
    "# Saving the Datasets\n",
    "\n",
    "Now we will save them for later testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "removed_folder = 'data/removed'\n",
    "restored_folder = 'data/restored'\n",
    "\n",
    "for i, datasets in enumerate(sampled_datasets_removal):\n",
    "    for j, dataset in enumerate(datasets):\n",
    "        if i == 0:\n",
    "            wine_type = 'red'\n",
    "        else:\n",
    "            wine_type = 'white'\n",
    "        filename = f'{wine_type}_wine_{(j+1)*10}.csv'\n",
    "        filepath = os.path.join(removed_folder, filename)\n",
    "        dataset.to_csv(filepath, index=False, sep=';')\n",
    "\n",
    "for i, datasets in enumerate(sampled_datasets_restored):\n",
    "    for j, dataset in enumerate(datasets):\n",
    "        if i == 0:\n",
    "            wine_type = 'red'\n",
    "        else:\n",
    "            wine_type = 'white'\n",
    "        filename = f'{wine_type}_wine_{(j+1)*10}.csv'\n",
    "        filepath = os.path.join(restored_folder, filename)\n",
    "        dataset.to_csv(filepath, index=False, sep=';')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
